{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: astropy.extern.six will be removed in 4.0, use the six module directly if it is still needed [astropy.extern.six]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "from halotools.sim_manager import CachedHaloCatalog\n",
    "from halotools.mock_observables import wp\n",
    "from halotools.empirical_models import PrebuiltHodModelFactory\n",
    "from tabcorr import TabCorr\n",
    "\n",
    "import pandas as pd\n",
    "from halotools.sim_manager import UserSuppliedHaloCatalog, UserSuppliedPtclCatalog,FakeSim\n",
    "from halotools.mock_observables import delta_sigma, wp, return_xyz_formatted_array\n",
    "from halotools.empirical_models import NFWProfile\n",
    "from halotools.empirical_models import PrebuiltHodModelFactory, HodModelFactory\n",
    "from halotools.empirical_models import AssembiasZheng07Cens, AssembiasZheng07Sats, TrivialPhaseSpace, NFWPhaseSpace\n",
    "from halotools.utils import add_halo_hostid\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_halo_and_particle_catalogs_for_halotools(halo_catalog_path, particle_catalog_path):\n",
    "    halo_df = pd.read_csv(halo_catalog_path)\n",
    "    particles_df = pd.read_csv(particle_catalog_path, delimiter =' +',  names=['x','y','z'], engine='python')\n",
    "    print('Files read.')\n",
    "    \n",
    "    ptcl_x = particles_df['x'].values\n",
    "    ptcl_y = particles_df['y'].values\n",
    "    ptcl_z = particles_df['z'].values\n",
    "\n",
    "    particle_mass = 1.51e9\n",
    "    num_ptcl_per_dim = 3840\n",
    "    x = halo_df['x'].values\n",
    "    y = halo_df['y'].values\n",
    "    z = halo_df['z'].values\n",
    "    vx = halo_df['vx'].values\n",
    "    vy = halo_df['vy'].values\n",
    "    vz = halo_df['vz'].values\n",
    "    mass = halo_df['Mvir'].values\n",
    "    radius = halo_df['Rvir'].values/1e3 #convert to Mpc\n",
    "    ids = np.arange(0, len(halo_df))\n",
    "    upid = halo_df['upId'].values\n",
    "    simname = 'MDPL2'\n",
    "    \n",
    "    #get concentrations\n",
    "#     nfw = NFWProfile(redshift=redshift, cosmology = Planck15, mdef = 'vir', conc_mass_model = 'dutton_maccio14')\n",
    "#     model_conc = nfw.conc_NFWmodel(prim_haloprop = mass)\n",
    "    concentrations = halo_df['Rvir'].values / halo_df['Rs'].values\n",
    "    \n",
    "    print('Creating catalogs...')\n",
    "    particle_catalog = UserSuppliedPtclCatalog(x = ptcl_x, y = ptcl_y, z = ptcl_z, Lbox = Lbox, particle_mass = particle_mass,\n",
    "                                  redshift = redshift)\n",
    "    halo_catalog = UserSuppliedHaloCatalog(user_supplied_ptclcat = particle_catalog, redshift = redshift, simname = simname,\n",
    "                                       Lbox = Lbox, particle_mass = particle_mass, num_ptcl_per_dim =num_ptcl_per_dim,\n",
    "                                       halo_x = x, halo_y = y, halo_z = z,\n",
    "                                       halo_vx = vx, halo_vy = vy, halo_vz = vz, \n",
    "                                       halo_id = ids, halo_mvir = mass, halo_rvir = radius,\n",
    "                                       halo_nfw_conc = concentrations, halo_upid = upid )\n",
    "    \n",
    "    #add hostid\n",
    "    add_halo_hostid(halo_catalog.halo_table)\n",
    "    \n",
    "    return halo_catalog, particle_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '/Users/fardila/Documents/Data/baryonic_effects/CMASS/'\n",
    "queried_halo_cat_file = 'halo_catalogs/mdpl2_hlist_0.65650_Mvir11.2.csv'\n",
    "test_halo_cat_file = 'halo_catalogs/test.csv'\n",
    "### \"row_id\",\"Mvir\",\"Rvir\",\"M200c\",\"M500c\",\"x\",\"y\",\"z\",\"scale\"\n",
    "# full_halo_cat_file = 'halo_catalogs/cut_halo_df.pkl'\n",
    "particle_cat_file = 'particle_catalogs/mdpl2_particles_0.6565_10m.dat'\n",
    "test_particle_cat_file = 'particle_catalogs/test.dat'\n",
    "### \"x\",\"y\",\"z\"\n",
    "displacedA_particle_cat_file = 'particle_catalogs/MDPL2_bfc_particles_A.out'\n",
    "displacedB_particle_cat_file = 'particle_catalogs/MDPL2_bfc_particles_B.out'\n",
    "displacedC_particle_cat_file = 'particle_catalogs/MDPL2_bfc_particles_C.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift = (1./0.65650)-1. #z=0.523\n",
    "Lbox = 1000. #Mpc/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files read.\n",
      "Creating catalogs...\n"
     ]
    }
   ],
   "source": [
    "halo_catalog, particle_catalog = create_halo_and_particle_catalogs_for_halotools(data_directory+queried_halo_cat_file,\n",
    "                                                                                 data_directory+particle_cat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add to cache\n",
    "halo_catalog.add_halocat_to_cache(data_directory+'halo_catalogs/mdpl2_hlist_0.65650_Mvir11.2.hdf5', simname='mdpl2',\n",
    "                                 halo_finder='rockstar', version_name = 'Mvir_gtr_11.2', \n",
    "                                  processing_notes=' ',scale=0.65650)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# precompute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "\n",
    "# First, we tabulate the correlation functions in the halo catalog.\n",
    "rp_bins = np.logspace(-1, 1, 20)\n",
    "\n",
    "halotab = TabCorr.tabulate(halo_catalog, wp, rp_bins, pi_max=80,\n",
    "                           period=halo_catalog.Lbox)\n",
    "\n",
    "# We can save the result for later use.\n",
    "halotab.write('mdpl2_tabCorr.hdf5')\n",
    "\n",
    "print('{0} seconds'.format(time.time() - time1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could read it in like this. Thus, we can skip the previous steps in the\n",
    "# future.\n",
    "halotab = TabCorr.read('mdpl2_tabCorr.hdf5')\n",
    "\n",
    "# Now, we're ready to calculate correlation functions for a specific model.\n",
    "model = PrebuiltHodModelFactory('zheng07', threshold=-18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
